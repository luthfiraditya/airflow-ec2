[core]
# dags_folder = /opt/airflow/dags (Set by env var AIRFLOW__CORE__DAGS_FOLDER or default)
# base_log_folder = /opt/airflow/logs (Set by env var AIRFLOW__CORE__BASE_LOG_FOLDER or default)
# plugins_folder = /opt/airflow/plugins (Set by env var AIRFLOW__CORE__PLUGINS_FOLDER or default)
load_examples = False
# fernet_key = (Set by env var AIRFLOW__CORE__FERNET_KEY)
# executor = CeleryExecutor (Set by env var AIRFLOW__CORE__EXECUTOR)
# sql_alchemy_conn = (Set by env var AIRFLOW__DATABASE__SQL_ALCHEMY_CONN)
enable_xcom_pickling = True
dags_are_paused_at_creation = True
default_timezone = utc
# parallelism = 32
# dag_concurrency = 16
# max_active_runs_per_dag = 16

[webserver]
# web_server_host = 0.0.0.0 (Default)
# web_server_port = 8080 (Default)
# secret_key = (Generated by Airflow if not set, or set via env var AIRFLOW__WEBSERVER__SECRET_KEY)
expose_config = False # For security, don't expose config in UI
# rbac = True (Default in Airflow 2.x)

[celery]
# broker_url = (Set by env var AIRFLOW__CELERY__BROKER_URL)
# result_backend = (Set by env var AIRFLOW__CELERY__RESULT_BACKEND)
worker_concurrency = 4 # Adjust based on your EC2 instance size
# flower_host = 0.0.0.0
# flower_port = 5555

[logging]
# base_log_folder = /opt/airflow/logs
# remote_logging = False # Set to True if using S3, GCS, etc. for logs
# remote_log_conn_id = # Connection ID for remote logging
# remote_base_log_folder = # s3://bucket/path or gs://bucket/path
# logging_level = INFO
# fab_logging_level = WARN
# colored_console_log = True

[smtp]
# smtp_host = (Set by env var AIRFLOW__SMTP__SMTP_HOST)
# smtp_port = (Set by env var AIRFLOW__SMTP__SMTP_PORT)
# smtp_user = (Set by env var AIRFLOW__SMTP__SMTP_USER)
# smtp_password = (Set by env var AIRFLOW__SMTP__SMTP_PASSWORD)
# smtp_mail_from = (Set by env var AIRFLOW__SMTP__SMTP_MAIL_FROM)
# smtp_starttls = (Set by env var AIRFLOW__SMTP__SMTP_STARTTLS)
# smtp_ssl = (Set by env var AIRFLOW__SMTP__SMTP_SSL)

[metrics]
# statsd_on = False
# statsd_host = localhost
# statsd_port = 8125
# statsd_prefix = airflow